# ğŸ” Hybrid RAG Pipeline with LLaMA 3 (8B)

**Author:** TrÃ­ LÃª  
**Role:** AI/ML Practitioner | Final-year student @ Ton Duc Thang University  
**LLM:** `letri345/llama3-8b-merge` (Hugging Face)

---

## ğŸš€ Overview

This repository implements a **production-style Hybrid Retrieval-Augmented Generation (RAG) pipeline**, combining:

- **BM25 lexical retrieval**
- **Vector semantic search**
- **Reciprocal Rank Fusion (RRF)**
- **Context-aware prompt assembly**
- **Chat history memory routing**
- **Automated RAG evaluation**

The system is designed to improve **answer correctness, grounding, and relevance** for document-based QA.

---

## ğŸ§  Model

- **LLM:** `letri345/llama3-8b-merge`
- Architecture: LLaMA 3 â€“ 8B
- Optimized for:
  - Instruction-following
  - Context-grounded answering
  - Stable RAG evaluation

> â„¹ï¸ This Hugging Face model ID is required to reproduce all results in this repo.

---

## ğŸ—ï¸ System Architecture (Hybrid RAG)

```
User
 â†“
Router  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Chat History Memory
 â†“
Hybrid Retrieval
 â”œâ”€ BM25
 â””â”€ Vector Semantic Search (ChromaDB)
        â†“
Reciprocal Rank Fusion (RRF)
 â†“
Post-retrieval Processing
 (re-ranking, filtering, summarize)
 â†“
Contextual Prompt Assembly
 â†“
LLaMA 3 (8B)
 â†“
Answer
```

### Design Notes
- **Chat history feeds into the Router, not directly into the LLM**
- Prevents context pollution and improves retrieval precision
- Retrieval and generation are cleanly decoupled

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cache/
â”‚   â””â”€â”€ index_store/
â”‚
â”œâ”€â”€ Build_data.ipynb        # Document processing & indexing
â”œâ”€â”€ RAG.ipynb               # Retrieval, inference & evaluation
â”‚
â”œâ”€â”€ questions_full.csv      # Auto-generated evaluation questions
â”œâ”€â”€ eval_results.csv        # RAG evaluation outputs
â”œâ”€â”€ DMS-5.pdf               # Sample source document
â””â”€â”€ README.md
```

---

## ğŸ”§ Data & Indexing (`Build_data.ipynb`)

Pipeline:
1. Load raw documents
2. Chunking with overlap
3. Metadata extraction (doc_id, chunk_id, source)
4. Embedding generation
5. BM25 text preparation
6. Store vectors in **ChromaDB**

Outputs:
- Vector index
- BM25-ready corpus
- Node-level metadata

---

## ğŸ” Retrieval Strategy

### Hybrid Retrieval
- **BM25:** keyword precision
- **Vector search:** semantic similarity

### Fusion
- **Reciprocal Rank Fusion (RRF)** balances lexical & semantic signals
- Improves recall and ranking stability across query types

---

## âœï¸ Prompting & Inference

- Retrieved chunks are post-processed before inference
- Final prompt includes:
  - System instruction
  - Retrieved evidence
  - User query
- Ensures grounded, context-aware responses

---

## ğŸ“Š RAG Evaluation (`RAG.ipynb`)

### Evaluation Setup
- Semi-Automatic Question Generation (SAQG)
- Each question linked to reference context
- Answers evaluated by an LLM judge

### Metrics
| Metric | Scale |
|------|------|
| Correctness | 0 â€“ 5 |
| Faithfulness | 0 â€“ 1 |
| Relevancy | 0 â€“ 1 |

### Results (Average)
- **Correctness:** **4.24 / 5**
- **Faithfulness:** **0.86 / 1**
- **Relevancy:** **0.98 / 1**

â¡ Demonstrates strong grounding and high answer relevance.

---

## ğŸ¯ Use Cases

- Document-based QA systems
- Internal knowledge assistants
- RAG research & benchmarking
- AI/ML portfolio projects

---

## ğŸ‘¤ Author

**TrÃ­ LÃª**  
AI/ML Practitioner â€“ Final-year student @ Ton Duc Thang University  

Focused on:
- LLM fine-tuning
- RAG system design
- Evaluation-driven improvement

---

## ğŸ“œ License

For research and educational use.
